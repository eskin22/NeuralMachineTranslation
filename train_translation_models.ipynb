{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "rnn_encoder, rnn_decoder, transformer_encoder, transformer_decoder = None, None, None, None\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if __name__=='__main__':\n",
    "    print('Using device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     os.system(\"wget http://www.manythings.org/anki/spa-eng.zip\")\n",
    "#     import zipfile\n",
    "#     with zipfile.ZipFile('spa-eng.zip', 'r') as zip_ref:\n",
    "#         zip_ref.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    total_num_examples = 50000\n",
    "    dat = pd.read_csv(\"data/spa.txt\",\n",
    "                    sep=\"\\t\",\n",
    "                    header=None,\n",
    "                    usecols=[0,1],\n",
    "                    names=['eng', 'es'],\n",
    "                    nrows=total_num_examples,\n",
    "                    encoding=\"UTF-8\"\n",
    "    ).sample(frac=1).reset_index().drop(['index'], axis=1)\n",
    "\n",
    "    print(dat) # Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.process.helpers import preprocess_sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    data = dat.copy()\n",
    "    data['eng'] = dat.eng.apply(lambda w: preprocess_sentence(w))\n",
    "    data['es'] = dat.es.apply(lambda w: preprocess_sentence(w))\n",
    "    print(data) # Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # HYPERPARAMETERS (You may change these if you want, though you shouldn't need to)\n",
    "    BATCH_SIZE = 64\n",
    "    EMBEDDING_DIM = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.process.helpers import build_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    src_vocab_list = build_vocabulary(data['es'])\n",
    "    trg_vocab_list = build_vocabulary(data['eng'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.process.objects.vocabData import Vocab_Lang, MyData\n",
    "from src.process.helpers import preprocess_data_to_tensor, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    src_vocab = Vocab_Lang(src_vocab_list)\n",
    "    trg_vocab = Vocab_Lang(trg_vocab_list)\n",
    "\n",
    "    src_tensor, trg_tensor, max_length_src, max_length_trg = preprocess_data_to_tensor(data, src_vocab, trg_vocab)\n",
    "    src_tensor_train, src_tensor_val, trg_tensor_train, trg_tensor_val = train_test_split(src_tensor, trg_tensor)\n",
    "\n",
    "    # Create train and val datasets\n",
    "    train_dataset = MyData(src_tensor_train, trg_tensor_train)\n",
    "    train_dataset = DataLoader(train_dataset, batch_size=BATCH_SIZE, drop_last=True, shuffle=True)\n",
    "\n",
    "    test_dataset = MyData(src_tensor_val, trg_tensor_val)\n",
    "    test_dataset = DataLoader(test_dataset, batch_size=BATCH_SIZE, drop_last=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    idxes = random.choices(range(len(train_dataset.dataset)), k=5)\n",
    "    src, trg =  train_dataset.dataset[idxes]\n",
    "    print('Source:', src)\n",
    "    print('Source Dimensions: ', src.size())\n",
    "    print('Target:', trg)\n",
    "    print('Target Dimensions: ', trg.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction, corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation.sanityChecks import sanityCheckModel\n",
    "from src.models.rnn.encoder import RnnEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Set random seed\n",
    "    torch.manual_seed(42)\n",
    "    # Create test inputs\n",
    "    embedding_dim = [2, 5, 8]\n",
    "    hidden_units = [50, 100, 200]\n",
    "    sanity_vocab = Vocab_Lang(vocab=[\"a\", \"aa\", \"aaa\"])\n",
    "    params = []\n",
    "    inputs = []\n",
    "    for ed in embedding_dim:\n",
    "        for hu in hidden_units:\n",
    "            inp = {}\n",
    "            inp['src_vocab'] = sanity_vocab\n",
    "            inp['embedding_dim'] = ed\n",
    "            inp['hidden_units'] = hu\n",
    "            inputs.append(inp)\n",
    "    # Test init\n",
    "    expected_outputs = [8110, 31210, 122410, 8575, 32125, 124225, 9040, 33040, 126040]\n",
    "\n",
    "    sanityCheckModel(inputs, RnnEncoder, expected_outputs, \"init\")\n",
    "    print()\n",
    "\n",
    "    # Test forward\n",
    "    inputs = []\n",
    "    batch_sizes = [1, 2]\n",
    "    for hu in hidden_units:\n",
    "        for b in batch_sizes:\n",
    "            inp = {}\n",
    "            inp['embedding_dim'] = EMBEDDING_DIM\n",
    "            inp['src_vocab'] = sanity_vocab\n",
    "            inp[\"batch_size\"] = b\n",
    "            inp['hidden_units'] = hu\n",
    "            inputs.append(inp)\n",
    "    expected_outputs = [torch.Size([16, 1, 50]), torch.Size([16, 2, 50]), torch.Size([16, 1, 100]), torch.Size([16, 2, 100]), torch.Size([16, 1, 200]), torch.Size([16, 2, 200])]\n",
    "\n",
    "    sanityCheckModel(inputs, RnnEncoder, expected_outputs, \"forward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation.sanityChecks import sanityCheckDecoderModelForward\n",
    "from src.models.rnn.decoder import RnnDecoder\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Set random seed\n",
    "    torch.manual_seed(42)\n",
    "    # Create test inputs\n",
    "    embedding_dim = [2, 5, 8]\n",
    "    hidden_units = [50, 100, 200]\n",
    "    sanity_vocab = Vocab_Lang(vocab=[\"a\", \"aa\", \"aaa\"])\n",
    "    params = []\n",
    "    inputs = []\n",
    "    for ed in embedding_dim:\n",
    "        for hu in hidden_units:\n",
    "            inp = {}\n",
    "            inp['trg_vocab'] = sanity_vocab\n",
    "            inp['embedding_dim'] = ed\n",
    "            inp['hidden_units'] = hu\n",
    "            inputs.append(inp)\n",
    "    # Test init\n",
    "    expected_outputs = [21016, 82016, 324016, 21481, 82931, 325831, 21946, 83846, 327646]\n",
    "    sanityCheckModel(inputs, RnnDecoder, expected_outputs, \"init\")\n",
    "    print()\n",
    "\n",
    "    # Test forward\n",
    "    inputs = []\n",
    "    hidden_units = [50, 100, 200]\n",
    "    batch_sizes = [1, 2, 4]\n",
    "    embedding_dims = iter([50,80,100,120,150,200,300,400,500])\n",
    "    encoder_outputs = iter([torch.rand([16, 1, 50]), torch.rand([16, 2, 50]), torch.rand([16, 4, 50]), torch.rand([16, 1, 100]), torch.rand([16, 2, 100]), torch.rand([16, 4, 100]), torch.rand([16, 1, 200]), torch.rand([16, 2, 200]),torch.rand([16, 4, 200])])\n",
    "    expected_fc_outs = [torch.Size([1, 5]),torch.Size([2, 5]),torch.Size([4, 5]),torch.Size([1, 5]),torch.Size([2, 5]),torch.Size([4, 5]),torch.Size([1, 5]),torch.Size([2, 5]),torch.Size([4, 5])]\n",
    "    expected_dec_hs = [torch.Size([1, 1, 50]), torch.Size([1, 2, 50]), torch.Size([1, 4, 50]), torch.Size([1, 1, 100]), torch.Size([1, 2, 100]), torch.Size([1, 4, 100]), torch.Size([1, 1, 200]), torch.Size([1, 2, 200]), torch.Size([1, 4, 200])]\n",
    "    expected_attention_weights = [torch.Size([1, 16, 1]), torch.Size([2, 16, 1]), torch.Size([4, 16, 1]), torch.Size([1, 16, 1]), torch.Size([2, 16, 1]), torch.Size([4, 16, 1]), torch.Size([1, 16, 1]), torch.Size([2, 16, 1]), torch.Size([4, 16, 1])]\n",
    "    expected_outputs = (expected_fc_outs, expected_dec_hs, expected_attention_weights)\n",
    "\n",
    "    for hu in hidden_units:\n",
    "        for b in batch_sizes:\n",
    "            inp = {}\n",
    "            edim = next(embedding_dims)\n",
    "            inp['embedding_dim'] = edim\n",
    "            inp['trg_vocab'] = sanity_vocab\n",
    "            inp[\"batch_size\"] = b\n",
    "            inp['hidden_units'] = hu\n",
    "            inp['encoder_outputs'] = next(encoder_outputs)\n",
    "            inputs.append(inp)\n",
    "\n",
    "    sanityCheckDecoderModelForward(inputs, RnnDecoder, expected_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.rnn.encoder import RnnEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # HYPERPARAMETERS - feel free to change\n",
    "    LEARNING_RATE = 0.001\n",
    "    HIDDEN_UNITS=256\n",
    "    N_EPOCHS=10\n",
    "\n",
    "    rnn_encoder = RnnEncoder(src_vocab, EMBEDDING_DIM, HIDDEN_UNITS).to(DEVICE)\n",
    "    rnn_decoder = RnnDecoder(trg_vocab, EMBEDDING_DIM, HIDDEN_UNITS).to(DEVICE)\n",
    "\n",
    "    rnn_model_params = list(rnn_encoder.parameters()) + list(rnn_decoder.parameters())\n",
    "    optimizer = torch.optim.Adam(rnn_model_params, lr=LEARNING_RATE)\n",
    "\n",
    "    print('Encoder and Decoder models initialized!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.rnn.train import train_rnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_rnn_model(rnn_encoder, rnn_decoder, train_dataset, optimizer, trg_vocab, DEVICE, N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.rnn.inference import decode_rnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    rnn_encoder.eval()\n",
    "    rnn_decoder.eval()\n",
    "    idxes = random.choices(range(len(test_dataset.dataset)), k=5)\n",
    "    src, trg =  train_dataset.dataset[idxes]\n",
    "    curr_output, _ = decode_rnn_model(rnn_encoder, rnn_decoder, src.transpose(0,1).to(DEVICE), trg.size(1), DEVICE)\n",
    "    for i in range(len(src)):\n",
    "        print(\"Source sentence:\", ' '.join([x for x in [src_vocab.idx2word[j.item()] for j in src[i]] if x != '<pad>']))\n",
    "        print(\"Target sentence:\", ' '.join([x for x in [trg_vocab.idx2word[j.item()] for j in trg[i]] if x != '<pad>']))\n",
    "        print(\"Predicted sentence:\", ' '.join([x for x in [trg_vocab.idx2word[j.item()] for j in curr_output[i]] if x != '<pad>']))\n",
    "        print(\"----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.rnn.inference import evaluate_rnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    rnn_save_candidate, rnn_scores = evaluate_rnn_model(rnn_encoder, rnn_decoder, test_dataset, trg_tensor_val, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.transformer.encoder import TransformerEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    # Set random seed\n",
    "    torch.manual_seed(42)\n",
    "    # Create test inputs\n",
    "    dimf = [50, 100, 150]\n",
    "    embedding_dim = [4, 8, 12]\n",
    "    max_len = 16\n",
    "    num_layers = iter([1,1,1,2,2,2,3,3,3])\n",
    "    nheads = iter([1, 1, 1, 1, 2, 2, 2, 4, 4])\n",
    "    sanity_vocab = Vocab_Lang(vocab=[\"a\", \"aa\", \"aaa\"])\n",
    "    params = []\n",
    "    inputs = []\n",
    "    for df in dimf:\n",
    "        for ed in embedding_dim:\n",
    "            inp = {}\n",
    "            inp['src_vocab'] = sanity_vocab\n",
    "            inp['embedding_dim'] = ed\n",
    "            inp['num_heads'] = next(nheads)\n",
    "            inp['dim_feedforward'] = df\n",
    "            inp['num_layers'] = next(num_layers)\n",
    "            inp['max_len_src'] = max_len\n",
    "            inp['device'] = DEVICE\n",
    "            inputs.append(inp)\n",
    "    # Test init\n",
    "    expected_outputs = [570, 1218, 1994, 2020, 4096, 6428, 4370, 8674, 13362]\n",
    "\n",
    "    sanityCheckModel(inputs, TransformerEncoder, expected_outputs, \"init\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    # Set random seed\n",
    "    torch.manual_seed(42)\n",
    "    # Test forward\n",
    "    inputs = []\n",
    "    embedding_dims = [32,64,128]\n",
    "    batch_sizes = [1, 2]\n",
    "    dimf = 100\n",
    "    nheads = iter([1,1,2,2,4,4])\n",
    "    num_layers = iter([1,1,2,2,3,3])\n",
    "    max_len = 16\n",
    "    sanity_vocab = Vocab_Lang(vocab=[\"a\", \"aa\", \"aaa\"])\n",
    "    for ed in embedding_dims:\n",
    "        for b in batch_sizes:\n",
    "            inp = {}\n",
    "            inp['src_vocab'] = sanity_vocab\n",
    "            inp['embedding_dim'] = ed\n",
    "            inp['num_heads'] = next(nheads)\n",
    "            inp['dim_feedforward'] = dimf\n",
    "            inp['num_layers'] = next(num_layers)\n",
    "            inp['max_len_src'] = max_len\n",
    "            inp['device'] = DEVICE\n",
    "            inp[\"batch_size\"] = b\n",
    "            inputs.append(inp)\n",
    "    expected_outputs = [torch.Size([16, 1, 32]), torch.Size([16, 2, 32]), torch.Size([16, 1, 64]), torch.Size([16, 2, 64]), torch.Size([16, 1, 128]), torch.Size([16, 2, 128])]\n",
    "    # expected_outputs.to(DEVICE)\n",
    "\n",
    "    sanityCheckModel(inputs, TransformerEncoder, expected_outputs, \"forward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.transformer.decoder import TransformerDecoder\n",
    "from src.evaluation.sanityChecks import sanityCheckTransformerDecoderModelForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Set random seed\n",
    "    torch.manual_seed(42)\n",
    "    # Create test inputs\n",
    "    hidden_units = [50, 100, 200]\n",
    "    embedding_dim = [8, 16]\n",
    "    num_heads = [1, 2]\n",
    "    dim_feedforward = [50, 100]\n",
    "    num_layers = [1, 2]\n",
    "    max_lens = 64\n",
    "    sanity_vocab = Vocab_Lang(vocab=[\"a\", \"aa\", \"aaa\"])\n",
    "    params = []\n",
    "    inputs = []\n",
    "    for ed in embedding_dim:\n",
    "        for df in dim_feedforward:\n",
    "            for nh in num_heads:\n",
    "                for nl in num_layers:\n",
    "                    inp = {}\n",
    "                    inp['trg_vocab'] = sanity_vocab\n",
    "                    inp['embedding_dim'] = ed\n",
    "                    inp['num_heads'] = nh\n",
    "                    inp['num_layers'] = nl\n",
    "                    inp['dim_feedforward'] = df\n",
    "                    inp['max_len_trg'] = max_lens\n",
    "                    inp['device'] = DEVICE\n",
    "                    inputs.append(inp)\n",
    "    # Test init\n",
    "    expected_outputs = [1567, 3049, 1567, 3049, 2417, 4749, 2417, 4749]\n",
    "    sanityCheckModel(inputs, TransformerDecoder, expected_outputs, \"init\")\n",
    "    print()\n",
    "\n",
    "    # Test forward\n",
    "    inputs = []\n",
    "    batch_sizes = [1, 2, 4]\n",
    "    num_heads = 2\n",
    "    num_layers = 1\n",
    "    embedding_dims = iter([100, 100, 200, 200, 200, 400, 400, 800, 800])\n",
    "    max_lens = iter([16, 16, 16, 32, 32, 32, 64, 64, 128])\n",
    "    expected_outputs = [torch.Size([16, 1, 5]),torch.Size([16, 2, 5]),torch.Size([16, 4, 5]),torch.Size([32, 1, 5]),torch.Size([32, 2, 5]),torch.Size([32, 4, 5]),torch.Size([64, 1, 5]),torch.Size([64, 2, 5]),torch.Size([128, 4, 5])]\n",
    "\n",
    "    for hu in hidden_units:\n",
    "        for b in batch_sizes:\n",
    "            inp = {}\n",
    "            edim = next(embedding_dims)\n",
    "            inp['embedding_dim'] = edim\n",
    "            inp['trg_vocab'] = sanity_vocab\n",
    "            inp['num_heads'] = num_heads\n",
    "            inp['num_layers'] = num_layers\n",
    "            inp[\"batch_size\"] = b\n",
    "            inp['dim_feedforward'] = hu\n",
    "            inp['max_len_trg'] = next(max_lens)\n",
    "            inp['device'] = DEVICE\n",
    "            inputs.append(inp)\n",
    "\n",
    "    sanityCheckTransformerDecoderModelForward(inputs, TransformerDecoder, expected_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.transformer.train import train_transformer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # HYPERPARAMETERS - feel free to change\n",
    "    LEARNING_RATE = 0.001\n",
    "    DIM_FEEDFORWARD=512\n",
    "    N_EPOCHS=10\n",
    "    N_HEADS=2\n",
    "    N_LAYERS=2\n",
    "    DROPOUT=0.1\n",
    "\n",
    "    transformer_encoder = TransformerEncoder(src_vocab, EMBEDDING_DIM, N_HEADS,\n",
    "                                 N_LAYERS,DIM_FEEDFORWARD,\n",
    "                                 max_length_src, DEVICE, DROPOUT).to(DEVICE)\n",
    "    transformer_decoder = TransformerDecoder(trg_vocab, EMBEDDING_DIM, N_HEADS,\n",
    "                              N_LAYERS,DIM_FEEDFORWARD,\n",
    "                              max_length_trg, DEVICE, DROPOUT).to(DEVICE)\n",
    "\n",
    "    transformer_model_params = list(transformer_encoder.parameters()) + list(transformer_decoder.parameters())\n",
    "    optimizer = torch.optim.Adam(transformer_model_params, lr=LEARNING_RATE)\n",
    "\n",
    "    print('Encoder and Decoder models initialized!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_transformer_model(train_dataset, transformer_encoder, transformer_decoder, optimizer, DEVICE, N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.transformer.inference import decode_transformer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    transformer_encoder.eval()\n",
    "    transformer_decoder.eval()\n",
    "    idxes = random.choices(range(len(test_dataset.dataset)), k=5)\n",
    "    src, trg =  train_dataset.dataset[idxes]\n",
    "    curr_output, _, _ = decode_transformer_model(transformer_encoder, transformer_decoder, src.transpose(0,1).to(DEVICE), trg.size(1), DEVICE)\n",
    "    for i in range(len(src)):\n",
    "        print(\"Source sentence:\", ' '.join([x for x in [src_vocab.idx2word[j.item()] for j in src[i]] if x != '<pad>']))\n",
    "        print(\"Target sentence:\", ' '.join([x for x in [trg_vocab.idx2word[j.item()] for j in trg[i]] if x != '<pad>']))\n",
    "        print(\"Predicted sentence:\", ' '.join([x for x in [trg_vocab.idx2word[j.item()] for j in curr_output[i]] if x != '<pad>']))\n",
    "        print(\"----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.transformer.inference import evaluate_transformer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    transformer_save_candidate, transformer_scores = evaluate_transformer_model(transformer_encoder, transformer_decoder, test_dataset, trg_tensor_val, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    print()\n",
    "    if rnn_encoder is not None and rnn_decoder is not None:\n",
    "        print(\"Saving RNN model...\")\n",
    "        torch.save(rnn_encoder, 'models/rnn_encoder.pt')\n",
    "        torch.save(rnn_decoder, 'models/rnn_decoder.pt')\n",
    "        print(\"RNN model saved successfully.\\n\")\n",
    "    if transformer_encoder is not None and transformer_decoder is not None:\n",
    "        print(\"Saving Transformer model...\")\n",
    "        torch.save(transformer_encoder, 'models/transformer_encoder.pt')\n",
    "        torch.save(transformer_decoder, 'models/transformer_decoder.pt')\n",
    "        print(\"Transformer model saved successfully.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
